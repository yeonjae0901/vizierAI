import json
import os
from typing import Dict, Any, List, Optional
from openai import OpenAI
from app.config import settings

class LLMService:
    """Service for interacting with LLM"""
    
    def __init__(self):
        """Initialize LLM service with API key from settings"""
        try:
            api_key = os.environ.get("OPENAI_API_KEY") or settings.OPENAI_API_KEY
            if not api_key:
                print("ê²½ê³ : OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ì²´ ì‘ë‹µ ëª¨ë“œë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
                self.client = None
                self.model = None
                self.fake_mode = True
                return
                
            elif api_key.startswith("sk-your-") or api_key == "sk-your-valid-openai-api-key":
                print("ê²½ê³ : ê¸°ë³¸ OpenAI API í‚¤ê°€ ë³€ê²½ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëŒ€ì²´ ì‘ë‹µ ëª¨ë“œë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
                self.client = None
                self.model = None
                self.fake_mode = True
                return
            
            self.client = OpenAI(api_key=api_key)
            self.model = os.environ.get("LLM_MODEL") or settings.LLM_MODEL
            self.fake_mode = False
            print(f"LLM ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ - ì‚¬ìš© ëª¨ë¸: {self.model}")
        except Exception as e:
            print(f"LLM ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}. ëŒ€ì²´ ì‘ë‹µ ëª¨ë“œë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
            self.client = None
            self.model = None
            self.fake_mode = True
    
    async def call_llm(self, prompt: str, system_message: str = None) -> str:
        """
        Call LLM with prompt and optional system message
        
        Args:
            prompt: User prompt to send to LLM
            system_message: Optional system message for context
            
        Returns:
            LLM response as string
        """
        # API í‚¤ê°€ ì—†ê±°ë‚˜ ëŒ€ì²´ ëª¨ë“œì¸ ê²½ìš°
        if self.fake_mode:
            return self._generate_fallback_response(prompt, system_message)
            
        try:
            messages = []
            
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
            if system_message:
                messages.append({"role": "system", "content": system_message})
                
            # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì¶”ê°€
            messages.append({"role": "user", "content": prompt})
            
            # ChatCompletion API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.1
            )
            
            # ì‘ë‹µ ì¶”ì¶œ
            content = response.choices[0].message.content
            return content
        
        except Exception as e:
            print(f"LLM API í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}. ëŒ€ì²´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.")
            return self._generate_fallback_response(prompt, system_message)
    
    def _generate_fallback_response(self, prompt: str, system_message: str = None) -> str:
        """API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ì‘ë‹µ ìƒì„±"""
        print("ëŒ€ì²´ ì‘ë‹µ ìƒì„± ì¤‘...")
        
        # í”„ë¡¬í”„íŠ¸ì— 'ë¦¬í¬íŠ¸'ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if "ë¦¬í¬íŠ¸" in prompt.lower() or "report" in prompt.lower():
            return """# ğŸ” ë£° ë¶„ì„ ë¦¬í¬íŠ¸

## ğŸ“Œ ê¸°ë³¸ ì •ë³´
- **ìƒíƒœ**: API í‚¤ ë¯¸ì„¤ì •ìœ¼ë¡œ ì¸í•œ ëŒ€ì²´ ë¦¬í¬íŠ¸
- **ì„¤ëª…**: OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ìë™ ìƒì„±ëœ ëŒ€ì²´ ë¦¬í¬íŠ¸ì…ë‹ˆë‹¤.

## âš ï¸ ì„¤ì • í•„ìš”
OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”:

1. OpenAI API í‚¤ë¥¼ ë°œê¸‰ë°›ìœ¼ì„¸ìš”: https://platform.openai.com/account/api-keys
2. í™˜ê²½ ë³€ìˆ˜ 'OPENAI_API_KEY'ì— ë°œê¸‰ë°›ì€ í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.
3. ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ì„¸ìš”.

## ğŸ“ ê´€ë¦¬ì ì•ˆë‚´
- í™˜ê²½ ë³€ìˆ˜ë¡œ API í‚¤ ì„¤ì •: `export OPENAI_API_KEY=your-key-here`
- í™˜ê²½ íŒŒì¼(.env)ì— API í‚¤ ì„¤ì •: `OPENAI_API_KEY=your-key-here`

ì •ìƒì ì¸ ë¦¬í¬íŠ¸ ìƒì„±ì„ ìœ„í•´ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."""
        
        # ê·¸ ì™¸ ì¼ë°˜ì ì¸ ìš”ì²­ì¸ ê²½ìš°
        return "LLM ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
    
    async def generate_json(self, prompt: str, system_message: str = None) -> Dict[str, Any]:
        """
        Generate JSON from prompt
        
        Args:
            prompt: User prompt describing what JSON to generate
            system_message: Optional system message for context
            
        Returns:
            Generated JSON as dict
            
        Raises:
            ValueError: If API key is not set
            Exception: If API call fails or JSON parsing fails
        """
        if system_message is None:
            system_message = "You are a helpful assistant that generates valid JSON based on user requirements. Always respond with valid JSON only."
        
        response = await self.call_llm(prompt, system_message)
        
        # Extract JSON from response (handling cases where LLM might add markdown code blocks)
        json_str = response
        if "```json" in response:
            json_str = response.split("```json")[1].split("```")[0].strip()
        elif "```" in response:
            json_str = response.split("```")[1].split("```")[0].strip()
        
        try:
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}, ì‘ë‹µ: {response}")
            raise Exception(f"LLM ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}") 